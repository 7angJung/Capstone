{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2108c81-6974-4451-bdbf-c5003c44d4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: easyocr in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (1.7.1)\n",
      "Requirement already satisfied: torch in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from easyocr) (2.2.1)\n",
      "Requirement already satisfied: torchvision>=0.5 in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from easyocr) (0.17.1)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (4.8.0.74)\n",
      "Requirement already satisfied: scipy in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (1.12.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (1.26.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (10.2.0)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from easyocr) (0.22.0)\n",
      "Requirement already satisfied: python-bidi in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (0.4.2)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (6.0.1)\n",
      "Requirement already satisfied: Shapely in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (2.0.3)\n",
      "Requirement already satisfied: pyclipper in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (1.3.0.post5)\n",
      "Requirement already satisfied: ninja in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (1.11.1.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch->easyocr) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch->easyocr) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch->easyocr) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch->easyocr) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch->easyocr) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch->easyocr) (2024.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from python-bidi->easyocr) (1.16.0)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from scikit-image->easyocr) (2.34.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from scikit-image->easyocr) (2024.2.12)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from scikit-image->easyocr) (23.2)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from scikit-image->easyocr) (0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from jinja2->torch->easyocr) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from sympy->torch->easyocr) (1.3.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: torch in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (2.2.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (0.17.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (4.8.0.74)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from opencv-python-headless) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n"
     ]
    }
   ],
   "source": [
    "# OCR 모델\n",
    "!pip install easyocr\n",
    "# 이미지 영상 처리\n",
    "!pip install opencv-python\n",
    "# PyTorch와 torchvision 설치\n",
    "!pip install torch torchvision torchaudio\n",
    "# matplotlib 설치\n",
    "!pip install matplotlib\n",
    "# GUI 없는 환경에서 OpenCV 사용을 위해\n",
    "!pip install opencv-python-headless\n",
    "# clone\n",
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70399511-1be8-4025-81f4-cd17511e2e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['pillow>=10.3.0'] not found, attempting AutoUpdate...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  AutoUpdate skipped (offline)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\peter/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-5-1 Python-3.12.2 torch-2.2.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일을 찾을 수 없습니다: peter/capstone/camera/test5.jpg\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'peter/capstone/camera/test5.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m파일을 찾을 수 없습니다: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m results \u001b[38;5;241m=\u001b[39m model(img)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Results\u001b[39;00m\n\u001b[0;32m     23\u001b[0m results\u001b[38;5;241m.\u001b[39mprint()  \u001b[38;5;66;03m# or .show(), .save(), .crop(), .pandas(), etc.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:835\u001b[0m, in \u001b[0;36mAutoShape.forward\u001b[1;34m(self, ims, size, augment, profile)\u001b[0m\n\u001b[0;32m    833\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# filename\u001b[39;00m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(im, (\u001b[38;5;28mstr\u001b[39m, Path)):  \u001b[38;5;66;03m# filename or uri\u001b[39;00m\n\u001b[1;32m--> 835\u001b[0m     im, f \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(requests\u001b[38;5;241m.\u001b[39mget(im, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mraw \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(im)\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m im), im\n\u001b[0;32m    836\u001b[0m     im \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(exif_transpose(im))\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(im, Image\u001b[38;5;241m.\u001b[39mImage):  \u001b[38;5;66;03m# PIL Image\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\capstone\\Lib\\site-packages\\PIL\\Image.py:3247\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3244\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3247\u001b[0m     fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3248\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'peter/capstone/camera/test5.jpg'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\")  # or yolov5n - yolov5x6, custom\n",
    "\n",
    "# Images\n",
    "img = \"capstone/camera/test5.jpg\"  # or file, Path, PIL, OpenCV, numpy, list\n",
    "\n",
    "# 파일이 존재하는지 확인\n",
    "if os.path.exists(img):\n",
    "    # 파일이 존재하면 처리 진행\n",
    "    print(f\"파일이 존재합니다: {img}\")\n",
    "    # 여기에 이미지 처리 코드를 추가하세요.\n",
    "else:\n",
    "    # 파일이 존재하지 않으면 경고 메시지 출력\n",
    "    print(f\"파일을 찾을 수 없습니다: {img}\")\n",
    "\n",
    "# Inference\n",
    "results = model(img)\n",
    "\n",
    "# Results\n",
    "results.print()  # or .show(), .save(), .crop(), .pandas(), etc.\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347712c6-65f1-4b28-ad19-899febff7281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# 모델 로드\n",
    "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\")  # YOLOv5 모델 버전 선택\n",
    "\n",
    "# 이미지 경로\n",
    "img_path = \"capstone/camera/test5.jpg\"\n",
    "\n",
    "# 추론 수행\n",
    "results = model(img_path)\n",
    "\n",
    "# detected된 모든 객체를 pandas 데이터프레임 형태로 변환\n",
    "df = results.pandas().xyxy[0]\n",
    "\n",
    "# 'book' 클래스의 객체들만 필터링\n",
    "book_df = df[df['name'] == 'book']\n",
    "\n",
    "# confidence가 가장 높은 'book' 객체 찾기\n",
    "if not book_df.empty:\n",
    "    highest_conf_row = book_df.loc[book_df['confidence'].idxmax()]\n",
    "    \n",
    "    # 이미지 로드\n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    # 바운딩 박스로 이미지 자르기\n",
    "    cropped = img.crop((int(highest_conf_row['xmin']), int(highest_conf_row['ymin']), int(highest_conf_row['xmax']), int(highest_conf_row['ymax'])))\n",
    "    \n",
    "    # 자른 이미지의 너비와 높이 구하기\n",
    "    width, height = cropped.size\n",
    "    \n",
    "    # 이미지를 가로로 반으로 나누기\n",
    "    left_half = cropped.crop((0, 0, width/2, height))\n",
    "    right_half = cropped.crop((width/2, 0, width, height))\n",
    "    \n",
    "    # 나눠진 이미지 파일 저장\n",
    "    left_half_path = 'capstone/onePage/left_half.jpg'\n",
    "    right_half_path = 'capstone/onePage/right_half.jpg'\n",
    "    left_half.save(left_half_path)\n",
    "    right_half.save(right_half_path)\n",
    "else:\n",
    "    print(\"탐지된 'book'이 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7a9ec8-36a2-492e-83b9-3b6814445d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "\n",
    "# easyocr Reader 생성 (한국어와 영어 인식을 위해 'ko'와 'en'을 설정)\n",
    "reader = easyocr.Reader(['ko', 'en'], gpu=False)\n",
    "\n",
    "# 이미지 경로\n",
    "left_half_path = 'capstone/onePage/left_half.jpg'\n",
    "right_half_path = 'capstone/onePage/right_half.jpg'\n",
    "\n",
    "# 이미지 읽기\n",
    "left_img = cv2.imread(left_half_path)\n",
    "right_img = cv2.imread(right_half_path)\n",
    "\n",
    "# 텍스트를 저장할 리스트 초기화\n",
    "recognized_texts = []\n",
    "\n",
    "# 왼쪽 이미지에서 텍스트 인식 및 바운드 박스 그리기\n",
    "result_left = reader.readtext(left_img)\n",
    "for (bbox, text, prob) in result_left:\n",
    "    # 인식된 텍스트를 리스트에 추가\n",
    "    recognized_texts.append(text)\n",
    "    # 바운드 박스 좌표 추출 및 그리기\n",
    "    (top_left, top_right, bottom_right, bottom_left) = bbox\n",
    "    top_left = (int(top_left[0]), int(top_left[1]))\n",
    "    bottom_right = (int(bottom_right[0]), int(bottom_right[1]))\n",
    "    cv2.rectangle(left_img, top_left, bottom_right, (0, 255, 0), 2)\n",
    "\n",
    "# 왼쪽 이미지 저장 및 표시\n",
    "cv2.imwrite('capstone/onePage/test5_left.jpg', left_img)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cv2.cvtColor(left_img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Left Page with Bounding Boxes\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# 오른쪽 이미지에서 텍스트 인식 및 바운드 박스 그리기\n",
    "result_right = reader.readtext(right_img)\n",
    "for (bbox, text, prob) in result_right:\n",
    "    # 인식된 텍스트를 리스트에 추가\n",
    "    recognized_texts.append(text)\n",
    "    # 바운드 박스 좌표 추출 및 그리기\n",
    "    (top_left, top_right, bottom_right, bottom_left) = bbox\n",
    "    top_left = (int(top_left[0]), int(top_left[1]))\n",
    "    bottom_right = (int(bottom_right[0]), int(bottom_right[1]))\n",
    "    cv2.rectangle(right_img, top_left, bottom_right, (0, 255, 0), 2)\n",
    "\n",
    "# 오른쪽 이미지 저장 및 표시\n",
    "cv2.imwrite('capstone/onePage/test5_right.jpg', right_img)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cv2.cvtColor(right_img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Right Page with Bounding Boxes\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# 인식된 텍스트 리스트 출력\n",
    "print(\"인식된 텍스트들:\")\n",
    "for text in recognized_texts:\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b59a6-5719-4e66-af07-56b1d3aafbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "\n",
    "# easyocr Reader 생성 (한국어와 영어 인식을 위해 'ko'와 'en'을 설정)\n",
    "reader = easyocr.Reader(['ko', 'en'], gpu=False)\n",
    "\n",
    "# 이미지 경로\n",
    "path = 'capstone/camera/test1.jpg'\n",
    "\n",
    "# 이미지 읽기\n",
    "img = cv2.imread(path)\n",
    "\n",
    "# 텍스트를 저장할 리스트 초기화\n",
    "recognized_texts = []\n",
    "\n",
    "# 왼쪽 이미지에서 텍스트 인식 및 바운드 박스 그리기\n",
    "result = reader.readtext(img)\n",
    "\n",
    "for (bbox, text, prob) in result:\n",
    "    # 인식된 텍스트를 리스트에 추가\n",
    "    recognized_texts.append(text)\n",
    "    # 바운드 박스 좌표 추출 및 그리기\n",
    "    (top_left, top_right, bottom_right, bottom_left) = bbox\n",
    "    top_left = (int(top_left[0]), int(top_left[1]))\n",
    "    bottom_right = (int(bottom_right[0]), int(bottom_right[1]))\n",
    "    cv2.rectangle(left_img, top_left, bottom_right, (0, 255, 0), 2)\n",
    "\n",
    "# 왼쪽 이미지 저장 및 표시\n",
    "cv2.imwrite('capstone/camera/test1.jpg', img)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Page with Bounding Boxes\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# 인식된 텍스트 리스트 출력\n",
    "print(\"인식된 텍스트들:\")\n",
    "for text in recognized_texts:\n",
    "    print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
