{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6dc5f6f-a4d0-4553-be8c-bce54722095d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from flask) (3.0.2)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from flask) (1.8.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from Jinja2>=3.1.2->flask) (2.1.3)\n",
      "Requirement already satisfied: pyserial in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: nbimporter in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (0.3.4)\n",
      "Requirement already satisfied: torch in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (2.2.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (0.17.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook text_processing.ipynb to script\n",
      "[NbConvertApp] Writing 5212 bytes to text_processing.py\n",
      "[NbConvertApp] Converting notebook camera_operation.ipynb to script\n",
      "[NbConvertApp] Writing 675 bytes to camera_operation.py\n",
      "[NbConvertApp] Converting notebook braille_translate.ipynb to script\n",
      "[NbConvertApp] Writing 8351 bytes to braille_translate.py\n"
     ]
    }
   ],
   "source": [
    "!pip install flask\n",
    "!pip install pyserial\n",
    "!pip install opencv-python\n",
    "!pip install nbimporter\n",
    "!pip install torch torchaudio torchvision\n",
    "!jupyter nbconvert --to script text_processing.ipynb\n",
    "!jupyter nbconvert --to script camera_operation.ipynb\n",
    "!jupyter nbconvert --to script braille_translate.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f18eed4-2f19-4000-8cc6-98dcc9d17928",
   "metadata": {},
   "outputs": [
    {
     "ename": "SerialException",
     "evalue": "could not open port 'COM7': FileNotFoundError(2, '지정된 파일을 찾을 수 없습니다.', None, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSerialException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m app \u001b[38;5;241m=\u001b[39m Flask(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 연결할 시리얼 포트와 baudrate 설정\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m ser \u001b[38;5;241m=\u001b[39m serial\u001b[38;5;241m.\u001b[39mSerial(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOM7\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m9600\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# 변수 초기화\u001b[39;00m\n\u001b[0;32m     21\u001b[0m camera \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\capstone\\Lib\\site-packages\\serial\\serialwin32.py:33\u001b[0m, in \u001b[0;36mSerial.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_overlapped_read \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_overlapped_write \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28msuper\u001b[39m(Serial, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\capstone\\Lib\\site-packages\\serial\\serialutil.py:244\u001b[0m, in \u001b[0;36mSerialBase.__init__\u001b[1;34m(self, port, baudrate, bytesize, parity, stopbits, timeout, xonxoff, rtscts, write_timeout, dsrdtr, inter_byte_timeout, exclusive, **kwargs)\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munexpected keyword arguments: \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(kwargs))\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m port \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 244\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\capstone\\Lib\\site-packages\\serial\\serialwin32.py:64\u001b[0m, in \u001b[0;36mSerial.open\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_port_handle \u001b[38;5;241m==\u001b[39m win32\u001b[38;5;241m.\u001b[39mINVALID_HANDLE_VALUE:\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_port_handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m    \u001b[38;5;66;03m# 'cause __del__ is called anyway\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SerialException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not open port \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mportstr, ctypes\u001b[38;5;241m.\u001b[39mWinError()))\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_overlapped_read \u001b[38;5;241m=\u001b[39m win32\u001b[38;5;241m.\u001b[39mOVERLAPPED()\n",
      "\u001b[1;31mSerialException\u001b[0m: could not open port 'COM7': FileNotFoundError(2, '지정된 파일을 찾을 수 없습니다.', None, 2)"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, Response, request, jsonify\n",
    "import serial\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import threading\n",
    "import subprocess\n",
    "import nbimporter\n",
    "import io\n",
    "from PIL import Image\n",
    "from camera_operation import taking_picture\n",
    "from text_processing import text_correction, text_detection\n",
    "from braille_translate import text_to_braille\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# 연결할 시리얼 포트와 baudrate 설정\n",
    "ser = serial.Serial('COM7', 9600)\n",
    "\n",
    "# 변수 초기화\n",
    "camera = cv2.VideoCapture(1)\n",
    "camera.set(cv2.CAP_PROP_FRAME_WIDTH, 1080) \n",
    "camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "recognized_texts_global = [] # 인식된 텍스트 리스트\n",
    "current_text_index = 0 # 리스트 위치 변수 <- 초기값을 0으로 설정\n",
    "braille_texts = []\n",
    "labelled_img_path = None\n",
    "word = \"\"\n",
    "last_arduino_message = \"\"  # Arduino로부터 받은 마지막 메시지를 저장하는 변수\n",
    "current_status_message = \"\" # 현재 진행상황\n",
    "\n",
    "def read_from_port(ser):\n",
    "    global recognized_texts_global, current_text_index, braille_texts, labelled_img_path, word, last_arduino_message, current_status_message\n",
    "    \n",
    "    while True:\n",
    "        reading = ser.readline().decode().strip()\n",
    "        current_status_message = \"촬영 버튼을 누르기 전 책을 화면과 같이 왼쪽 페이지와 오른쪽 페이지를 구분할 수 있도록 배치하십시오. 만약 책이 아니라 문서를 인식하고 싶으시다면 왼쪽 페이지 부분에 문서를 배치해주시기 바랍니다.\"\n",
    "        \n",
    "        print(\"===============  Received from Arduino -> \", reading, \"  ===============\")\n",
    "        if reading == \"Take Picture\":\n",
    "            # 메시지 업데이트\n",
    "            last_arduino_message = \"촬영 버튼\"\n",
    "            \n",
    "            # 1 - 이미지 촬영\n",
    "            print(\"< 1 - 이미지 촬영 >\")\n",
    "            img_path = taking_picture(camera)\n",
    "\n",
    "            # 널값인지 검사\n",
    "            if img_path is None:\n",
    "                current_status_message = \"[Error] 이미지 촬영에 실패했습니다. 카메라를 확인하시고 다시 촬영해주세요.\"\n",
    "                continue\n",
    "            else:\n",
    "                current_status_message = \"이미지 촬영이 완료됐습니다. 텍스트 인식을 진행합니다.\"\n",
    "            \n",
    "            # 2 - 텍스트 인식\n",
    "            print(\"< 2 - 텍스트 인식 >\")\n",
    "            recognized_texts, labelled_img_path = text_detection(img_path)\n",
    "                \n",
    "            # 인식된 텍스트 처리\n",
    "            words_list = [word for text in recognized_texts for word in text.split()]\n",
    "            try:\n",
    "                corrected_texts = text_correction(words_list)\n",
    "            except ValueError as e:\n",
    "                print(f\"예외 발생: {e}\")\n",
    "                continue\n",
    "            \n",
    "            filtered_texts = [text for text in corrected_texts if text.strip()]\n",
    "            print(\"인식된 텍스트 >>> \", filtered_texts)\n",
    "            recognized_texts_global = filtered_texts  # 새로운 텍스트로 업데이트\n",
    "            current_text_index = 0  # 새로운 텍스트 리스트로 업데이트되면 인덱스 초기화\n",
    "            current_status_message = \"텍스트 인식이 완료됐습니다. \" + \", \".join([text for text in recognized_texts_global])\n",
    "            \n",
    "            # 3 - 텍스트를 점자로 변환하여 저장\n",
    "            print(\"< 3 - 텍스트 점자로 변환 >\")\n",
    "            braille_texts = text_to_braille(recognized_texts_global)\n",
    "            print(\"점자 텍스트 >>> \", braille_texts)\n",
    "            current_status_message = \"점자 변환이 완료됐습니다. 다음 단어 출력 버튼과 이전 버튼 출력을 눌러 점자 확인이 가능합니다.\"\n",
    "            \n",
    "        elif reading == \"Next\":\n",
    "            # 메시지 업데이트\n",
    "            current_status_message = \"다음 단어 출력 버튼이 입력됐습니다.\"\n",
    "            last_arduino_message = \"다음 단어 출력 버튼\"\n",
    "            next_text()\n",
    "            \n",
    "        elif reading == \"Previous\":\n",
    "            # 메시지 업데이트\n",
    "            current_status_message = \"이전 단어 출력 버튼이 입력됐습니다.\"\n",
    "            last_arduino_message = \"이전 단어 출력 버튼\"\n",
    "            previous_text()\n",
    "\n",
    "def next_text():\n",
    "    global current_text_index, word, current_status_message, recognized_texts_global, braille_texts\n",
    "    \n",
    "    if len(recognized_texts_global) == 0:\n",
    "        current_status_message = \"리스트가 비어있습니다. 촬영부터 진행해주세요.\"\n",
    "        print(\"[Warning] 리스트가 비어있습니다.\")\n",
    "        \n",
    "    elif current_text_index < len(recognized_texts_global):\n",
    "        word = recognized_texts_global[current_text_index]\n",
    "        braille = braille_texts[current_text_index]\n",
    "        send_text_to_arduino(word, braille)\n",
    "        current_text_index += 1  # 인덱스를 나중에 증가\n",
    "        \n",
    "    else:\n",
    "        current_status_message = \"인식된 텍스트를 다 읽었습니다.\"\n",
    "        print(\"리스트의 끝점입니다.\")\n",
    "\n",
    "def previous_text():\n",
    "    global current_text_index, word, current_status_message, recognized_texts_global, braille_texts   \n",
    "    \n",
    "    if len(recognized_texts_global) == 0:\n",
    "        current_status_message = \"리스트가 비어있습니다. 촬영부터 진행해주세요.\"\n",
    "        print(\"[Warning] 리스트가 비어있습니다.\")      \n",
    "    \n",
    "    elif current_text_index > 0:\n",
    "        current_text_index -= 1\n",
    "        word = recognized_texts_global[current_text_index]\n",
    "        braille = braille_texts[current_text_index]\n",
    "        send_text_to_arduino(word, braille)       \n",
    "    \n",
    "    else:\n",
    "        current_status_message = \"첫 번째 텍스트이므로 그 이전 단어가 없습니다.\"\n",
    "        print(\"리스트의 시작점입니다.\")\n",
    "\n",
    "def send_text_to_arduino(text, braille):\n",
    "    print(\"단어:\", text)\n",
    "    print(\"점자:\", braille)\n",
    "    ser.write((braille + \"\\n\").encode())\n",
    "\n",
    "def generate_frames():\n",
    "    while True:\n",
    "        success, frame = camera.read()  # 카메라로부터 프레임 읽기\n",
    "        if not success:\n",
    "            break\n",
    "        else:\n",
    "            # 프레임 크기 가져오기\n",
    "            height, width, _ = frame.shape\n",
    "\n",
    "            # 중앙선 그리기\n",
    "            center_x = width // 2\n",
    "            cv2.line(frame, (center_x, 0), (center_x, height), (0, 255, 0), 2)\n",
    "\n",
    "            # 텍스트 출력\n",
    "            cv2.putText(frame, 'Left Page', (50, height // 2), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame, 'Right Page', (center_x + 270, height // 2), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            # JPEG 형식으로 인코딩\n",
    "            ret, buffer = cv2.imencode('.jpg', frame)\n",
    "            frame = buffer.tobytes()\n",
    "\n",
    "            yield (b'--frame\\r\\n'\n",
    "                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
    "            \n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('final_index.html')\n",
    "\n",
    "@app.route('/video')\n",
    "def video():\n",
    "    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "@app.route('/labelled_image')\n",
    "def labelled_image():\n",
    "    img = cv2.imread(labelled_img_path)\n",
    "    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    img_io = io.BytesIO()\n",
    "    img_pil.save(img_io, 'JPEG', quality=70)\n",
    "    img_io.seek(0)\n",
    "    return Response(img_io.getvalue(), mimetype='image/jpeg')\n",
    "\n",
    "@app.route('/arduino_received_message')\n",
    "def arduino_received_message():\n",
    "    # Arduino로부터 받은 마지막 메시지를 반환합니다.\n",
    "    return jsonify({\"message\": last_arduino_message})\n",
    "\n",
    "@app.route('/send_to_arduino')\n",
    "def send_to_arduino():\n",
    "    # Arduino로 보낸 문자열 반환\n",
    "    return jsonify({\"message\": word})\n",
    "\n",
    "@app.route('/current_status')\n",
    "def get_current_status():\n",
    "    # 현재 진행 상황을 출력\n",
    "    return jsonify({\"message\": current_status_message})\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    thread = threading.Thread(target=read_from_port, args=(ser,))\n",
    "    thread.start()\n",
    "    app.run(debug=False, host='0.0.0.0', port=5000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56feec3-94cf-4b9b-af65-171b29792635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
