{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "114ea639-c444-4a0a-b23d-9c8024aef2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from flask) (3.0.2)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from flask) (1.8.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from Jinja2>=3.1.2->flask) (2.1.3)\n",
      "Requirement already satisfied: pyserial in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: nbimporter in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (0.3.4)\n",
      "Requirement already satisfied: torch in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (2.2.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (0.17.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook text_processing.ipynb to script\n",
      "[NbConvertApp] Writing 5212 bytes to text_processing.py\n",
      "[NbConvertApp] Converting notebook camera_operation.ipynb to script\n",
      "[NbConvertApp] Writing 675 bytes to camera_operation.py\n",
      "[NbConvertApp] Converting notebook braille_translate.ipynb to script\n",
      "[NbConvertApp] Writing 8351 bytes to braille_translate.py\n"
     ]
    }
   ],
   "source": [
    "!pip install flask\n",
    "!pip install pyserial\n",
    "!pip install opencv-python\n",
    "!pip install nbimporter\n",
    "!pip install torch torchaudio torchvision\n",
    "!jupyter nbconvert --to script text_processing.ipynb\n",
    "!jupyter nbconvert --to script camera_operation.ipynb\n",
    "!jupyter nbconvert --to script braille_translate.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01bf633-94ec-4228-ab90-06ccfba0ab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, Response, request, jsonify\n",
    "import serial\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import threading\n",
    "import io\n",
    "from PIL import Image\n",
    "from camera_operation import taking_picture\n",
    "from text_processing import text_correction, text_detection\n",
    "from braille_translate import text_to_braille\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# 연결할 시리얼 포트와 baudrate 설정\n",
    "ser = serial.Serial('COM6', 9600)\n",
    "\n",
    "# 변수 초기화\n",
    "camera = cv2.VideoCapture(1)\n",
    "camera.set(cv2.CAP_PROP_FRAME_WIDTH, 1080) \n",
    "camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "recognized_texts_global = []  # 인식된 텍스트 리스트\n",
    "current_text_index = -1  # 리스트 위치 변수\n",
    "braille_texts = []\n",
    "labelled_img_path = None\n",
    "word = \"\"\n",
    "last_arduino_message = \"\"  # Arduino로부터 받은 마지막 메시지를 저장하는 변수\n",
    "current_status_message = \"촬영 버튼을 누르기 전 책을 화면과 같이 왼쪽 페이지와 오른쪽 페이지를 구분할 수 있도록 배치하십시오.\"\n",
    "\n",
    "def read_from_port(ser):\n",
    "    global recognized_texts_global, current_text_index, braille_texts, labelled_img_path, word, last_arduino_message, current_status_message\n",
    "    \n",
    "    while True:\n",
    "        reading = ser.readline().decode().strip()\n",
    "        current_status_message = \"\"\n",
    "        \n",
    "        print(\"===============  Received from Arduino -> \", reading, \"  ===============\")\n",
    "        if reading == \"Take Picture\":\n",
    "            # 메시지 업데이트\n",
    "            last_arduino_message = \"촬영 버튼\"\n",
    "            \n",
    "            # 1 - 이미지 촬영\n",
    "            print(\"< 1 - 이미지 촬영 >\")\n",
    "            img_path = taking_picture(camera)\n",
    "\n",
    "            # 널값인지 검사\n",
    "            if img_path is None:\n",
    "                current_status_message = \"이미지 촬영에 실패했습니다. 카메라를 확인하시고 다시 촬영해주세요.\"\n",
    "                continue\n",
    "            else:\n",
    "                current_status_message = \"이미지 촬영이 완료됐습니다. 텍스트 인식을 진행합니다.\"\n",
    "            \n",
    "            # 2 - 텍스트 인식\n",
    "            print(\"< 2 - 텍스트 인식 >\")\n",
    "            recognized_texts, labelled_img_path = text_detection(img_path)\n",
    "\n",
    "            # 인식된 텍스트 처리\n",
    "            words_list = [word for text in recognized_texts for word in text.split()]\n",
    "            try:\n",
    "                corrected_texts = text_correction(words_list)\n",
    "            except ValueError as e:\n",
    "                print(f\"예외 발생: {e}\")\n",
    "                continue\n",
    "            \n",
    "            filtered_texts = [text for text in corrected_texts if text.strip()]\n",
    "            print(\"인식된 텍스트 >>> \", filtered_texts)\n",
    "            recognized_texts_global = filtered_texts  # 새로운 텍스트로 업데이트\n",
    "            current_text_index = -1  # 새로운 텍스트 리스트로 업데이트되면 인덱스 초기화\n",
    "            \n",
    "            # 3 - 텍스트를 점자로 변환하여 저장\n",
    "            print(\"< 3 - 텍스트 점자로 변환 >\")\n",
    "            braille_texts = text_to_braille(recognized_texts_global)\n",
    "            print(\"점자 텍스트 >>> \", braille_texts)\n",
    "            current_status_message = \"점자 변환이 완료됐습니다. 다음 단어 출력 버튼과 이전 버튼 출력을 눌러 점자 확인이 가능합니다.\"\n",
    "            \n",
    "        elif reading == \"Next\":\n",
    "            last_arduino_message = \"다음 단어 출력 버튼\"\n",
    "            next_text()\n",
    "            \n",
    "        elif reading == \"Previous\":\n",
    "            last_arduino_message = \"이전 단어 출력 버튼\"\n",
    "            previous_text()\n",
    "\n",
    "def next_text():\n",
    "    global current_text_index, word, current_status_message, recognized_texts_global, braille_texts\n",
    "    \n",
    "    if len(recognized_texts_global) == 0:\n",
    "        current_status_message = \"리스트가 비어있습니다. 촬영부터 진행해주세요.\"\n",
    "        print(\"[Warning] 리스트가 비어있습니다.\")\n",
    "        \n",
    "    elif current_text_index < len(recognized_texts_global) - 1:\n",
    "        current_text_index += 1\n",
    "        word = recognized_texts_global[current_text_index]\n",
    "        send_text_to_arduino(word, braille_texts[current_text_index])\n",
    "    else:\n",
    "        current_status_message = \"인식된 텍스트를 다 읽었습니다. 페이지를 넘겨 촬영을 진행해주세요.\"\n",
    "        print(\"리스트의 끝점입니다.\")\n",
    "\n",
    "def previous_text():\n",
    "    global current_text_index, word, current_status_message, recognized_texts_global, braille_texts\n",
    "    \n",
    "    if len(recognized_texts_global) == 0:\n",
    "        current_status_message = \"리스트가 비어있습니다. 촬영부터 진행해주세요.\"\n",
    "        print(\"[Warning] 리스트가 비어있습니다.\")\n",
    "        \n",
    "    elif current_text_index > 0:\n",
    "        current_text_index -= 1\n",
    "        word = recognized_texts_global[current_text_index]\n",
    "        send_text_to_arduino(word, braille_texts[current_text_index])\n",
    "        \n",
    "    else:\n",
    "        current_status_message = \"첫 번째 텍스트이므로 그 이전 단어가 없습니다.\"\n",
    "        print(\"리스트의 시작점입니다.\")\n",
    "\n",
    "def send_text_to_arduino(text, braille):\n",
    "    print(\"단어:\", text)\n",
    "    print(\"점자:\", braille)\n",
    "    ser.write((braille + \"\\n\").encode())\n",
    "\n",
    "def generate_frames():\n",
    "    while True:\n",
    "        success, frame = camera.read()  # 카메라로부터 프레임 읽기\n",
    "        if not success:\n",
    "            break\n",
    "        else:\n",
    "            # 프레임 크기 가져오기\n",
    "            height, width, _ = frame.shape\n",
    "\n",
    "            # 중앙선 그리기\n",
    "            center_x = width // 2\n",
    "            cv2.line(frame, (center_x, 0), (center_x, height), (0, 255, 0), 2)\n",
    "\n",
    "            # 텍스트 출력\n",
    "            cv2.putText(frame, 'Left Page', (50, height // 2), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame, 'Right Page', (center_x + 270, height // 2), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            # JPEG 형식으로 인코딩\n",
    "            ret, buffer = cv2.imencode('.jpg', frame)\n",
    "            frame = buffer.tobytes()\n",
    "\n",
    "            yield (b'--frame\\r\\n'\n",
    "                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('kdn_index.html', initial_status_message=current_status_message)\n",
    "\n",
    "@app.route('/video')\n",
    "def video():\n",
    "    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "@app.route('/labelled_image')\n",
    "def labelled_image():\n",
    "    img = cv2.imread(labelled_img_path)\n",
    "    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    img_io = io.BytesIO()\n",
    "    img_pil.save(img_io, 'JPEG', quality=70)\n",
    "    img_io.seek(0)\n",
    "    return Response(img_io.getvalue(), mimetype='image/jpeg')\n",
    "\n",
    "@app.route('/arduino_received_message')\n",
    "def arduino_received_message():\n",
    "    # Arduino로부터 받은 마지막 메시지를 반환합니다.\n",
    "    return jsonify({\"message\": last_arduino_message})\n",
    "\n",
    "@app.route('/send_to_arduino')\n",
    "def send_to_arduino():\n",
    "    # Arduino로 보낸 문자열 반환\n",
    "    return jsonify({\"message\": word})\n",
    "\n",
    "@app.route('/current_status')\n",
    "def get_current_status():\n",
    "    # 현재 진행 상황을 출력\n",
    "    return jsonify({\"message\": current_status_message})\n",
    "\n",
    "@app.route('/current_braille')\n",
    "def current_braille():\n",
    "    if current_text_index >= 0 and current_text_index < len(braille_texts):\n",
    "        braille = braille_texts[current_text_index]\n",
    "        braille_images = []\n",
    "        \n",
    "        for char in braille:\n",
    "            img_src = f\"/static/braille_{char}.png\"  # 이미지 URL 생성\n",
    "            braille_images.append(img_src)\n",
    "        \n",
    "        return jsonify({\"braille_images\": braille_images})\n",
    "    else:\n",
    "        return jsonify({\"braille_images\": []})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    thread = threading.Thread(target=read_from_port, args=(ser,))\n",
    "    thread.start()\n",
    "    app.run(debug=False, host='0.0.0.0', port=5000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2952ae7f-7c3a-4d9b-9663-f657dcbfca15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
