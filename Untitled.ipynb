{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2108c81-6974-4451-bdbf-c5003c44d4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: easyocr in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (1.7.1)\n",
      "Requirement already satisfied: torch in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from easyocr) (2.2.1)\n",
      "Requirement already satisfied: torchvision>=0.5 in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from easyocr) (0.17.1)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from easyocr) (4.9.0.80)\n",
      "Requirement already satisfied: scipy in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (1.12.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (1.26.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (10.2.0)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from easyocr) (0.22.0)\n",
      "Requirement already satisfied: python-bidi in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (0.4.2)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (6.0.1)\n",
      "Requirement already satisfied: Shapely in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (2.0.3)\n",
      "Requirement already satisfied: pyclipper in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (1.3.0.post5)\n",
      "Requirement already satisfied: ninja in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (1.11.1.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch->easyocr) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch->easyocr) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch->easyocr) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch->easyocr) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch->easyocr) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch->easyocr) (2024.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from python-bidi->easyocr) (1.16.0)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from scikit-image->easyocr) (2.34.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from scikit-image->easyocr) (2024.2.12)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from scikit-image->easyocr) (23.2)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from scikit-image->easyocr) (0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from jinja2->torch->easyocr) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from sympy->torch->easyocr) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement python-opencv (from versions: none)\n",
      "ERROR: No matching distribution found for python-opencv\n"
     ]
    }
   ],
   "source": [
    "!pip install easyocr\n",
    "!pip install python-opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a66cfdfc-a3ac-4fd8-b94f-723580056f02",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m height \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1400\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# 이미지 크기 조정\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m resized_img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, (width, height), interpolation\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mINTER_LINEAR)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# 결과 이미지 저장\u001b[39;00m\n\u001b[0;32m     14\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/peter/OneDrive/바탕 화면/capstone(easyocr)/test2.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, resized_img)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# 이미지 로드\n",
    "img = cv2.imread('C:/Users/peter/OneDrive/바탕 화면/capstone(easyocr)/test2.jpg')\n",
    "\n",
    "# 새로운 크기 지정\n",
    "width = 1125\n",
    "height = 1400\n",
    "\n",
    "# 이미지 크기 조정\n",
    "resized_img = cv2.resize(img, (width, height), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "# 결과 이미지 저장\n",
    "cv2.imwrite('C:/Users/peter/OneDrive/바탕 화면/capstone(easyocr)/test2.jpg', resized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0623abf8-6685-4874-af70-7a2557bbf8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m reader \u001b[38;5;241m=\u001b[39m easyocr\u001b[38;5;241m.\u001b[39mReader([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mko\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# 이미지에서 텍스트 읽기\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m result \u001b[38;5;241m=\u001b[39m reader\u001b[38;5;241m.\u001b[39mreadtext(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/peter/OneDrive/바탕 화면/capstone(easyocr)/test2.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# 이미지를 OpenCV를 사용하여 읽기\u001b[39;00m\n\u001b[0;32m     14\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/peter/OneDrive/바탕 화면/capstone(easyocr)/test2.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\easyocr\\easyocr.py:468\u001b[0m, in \u001b[0;36mReader.readtext\u001b[1;34m(self, image, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, min_size, contrast_ths, adjust_contrast, filter_ths, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, y_ths, x_ths, add_margin, threshold, bbox_min_score, bbox_min_size, max_candidates, output_format)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;66;03m# get the 1st result from hor & free list as self.detect returns a list of depth 3\u001b[39;00m\n\u001b[0;32m    467\u001b[0m horizontal_list, free_list \u001b[38;5;241m=\u001b[39m horizontal_list[\u001b[38;5;241m0\u001b[39m], free_list[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 468\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize(img_cv_grey, horizontal_list, free_list,\\\n\u001b[0;32m    469\u001b[0m                         decoder, beamWidth, batch_size,\\\n\u001b[0;32m    470\u001b[0m                         workers, allowlist, blocklist, detail, rotation_info,\\\n\u001b[0;32m    471\u001b[0m                         paragraph, contrast_ths, adjust_contrast,\\\n\u001b[0;32m    472\u001b[0m                         filter_ths, y_ths, x_ths, \u001b[38;5;28;01mFalse\u001b[39;00m, output_format)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\easyocr\\easyocr.py:383\u001b[0m, in \u001b[0;36mReader.recognize\u001b[1;34m(self, img_cv_grey, horizontal_list, free_list, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, contrast_ths, adjust_contrast, filter_ths, y_ths, x_ths, reformat, output_format)\u001b[0m\n\u001b[0;32m    381\u001b[0m h_list \u001b[38;5;241m=\u001b[39m [bbox]\n\u001b[0;32m    382\u001b[0m f_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 383\u001b[0m image_list, max_width \u001b[38;5;241m=\u001b[39m get_image_list(h_list, f_list, img_cv_grey, model_height \u001b[38;5;241m=\u001b[39m imgH)\n\u001b[0;32m    384\u001b[0m result0 \u001b[38;5;241m=\u001b[39m get_text(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcharacter, imgH, \u001b[38;5;28mint\u001b[39m(max_width), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconverter, image_list,\\\n\u001b[0;32m    385\u001b[0m               ignore_char, decoder, beamWidth, batch_size, contrast_ths, adjust_contrast, filter_ths,\\\n\u001b[0;32m    386\u001b[0m               workers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    387\u001b[0m result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m result0\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\easyocr\\utils.py:582\u001b[0m, in \u001b[0;36mget_image_list\u001b[1;34m(horizontal_list, free_list, img, model_height, sort_output)\u001b[0m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_image_list\u001b[39m(horizontal_list, free_list, img, model_height \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m, sort_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    581\u001b[0m     image_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 582\u001b[0m     maximum_y,maximum_x \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    584\u001b[0m     max_ratio_hori, max_ratio_free \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m box \u001b[38;5;129;01min\u001b[39;00m free_list:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "\n",
    "# EasyOCR reader 초기화\n",
    "reader = easyocr.Reader(['ko', 'en'])\n",
    "\n",
    "# 이미지에서 텍스트 읽기\n",
    "result = reader.readtext('C:/Users/peter/OneDrive/바탕 화면/capstone(easyocr)/test2.jpg')\n",
    "\n",
    "# 이미지를 OpenCV를 사용하여 읽기\n",
    "img = cv2.imread('C:/Users/peter/OneDrive/바탕 화면/capstone(easyocr)/test2.jpg')\n",
    "\n",
    "# OpenCV 이미지를 PIL 이미지로 변환\n",
    "img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "font = ImageFont.truetype(\"malgun.ttf\", 40)\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "# 인식된 텍스트를 저장할 리스트 초기화\n",
    "recognized_texts = []\n",
    "\n",
    "# 인식된 텍스트와 바운딩 박스 그리기\n",
    "for i in result:\n",
    "    x = i[0][0][0]\n",
    "    y = i[0][0][1]\n",
    "    w = i[0][1][0] - i[0][0][0]\n",
    "    h = i[0][2][1] - i[0][1][1]\n",
    "\n",
    "    # 바운딩 박스 그리기\n",
    "    draw.rectangle(((x, y), (x+w, y+h)), outline=\"blue\", width=2)\n",
    "\n",
    "    # 텍스트 그리기\n",
    "    draw.text((int((x+x+w)/2), y-40), str(i[1]), font=font, fill=\"blue\")\n",
    "\n",
    "    # 인식된 텍스트를 리스트에 추가\n",
    "    recognized_texts.append(str(i[1]))\n",
    "\n",
    "# 결과 이미지 표시하기\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "# 인식된 텍스트들의 리스트 출력\n",
    "print(recognized_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7e4c73-15b5-47fb-a819-63cf4b945dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
