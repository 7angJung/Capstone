{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282333e3-16c4-4f6f-a1be-1e3d70690def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR 모델\n",
    "!pip install easyocr\n",
    "# 이미지 영상 처리\n",
    "!pip install opencv-python\n",
    "# PyTorch와 torchvision 설치\n",
    "!pip install torch torchvision torchaudio\n",
    "# matplotlib 설치\n",
    "!pip install matplotlib\n",
    "# GUI 없는 환경에서 OpenCV 사용을 위해\n",
    "!pip install opencv-python-headless\n",
    "# clone\n",
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76d38b5-b8dc-401e-82f0-3224a70c4602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import easyocr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageEnhance\n",
    "\n",
    "def detect_objects(image_path):\n",
    "    \"\"\"\n",
    "    객체 탐지 함수\n",
    "    \n",
    "    Parameters:\n",
    "    image_path (str): 탐지할 이미지의 경로\n",
    "    \"\"\"\n",
    "    # 모델 불러오기\n",
    "    model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\")  # 다양한 모델 옵션 사용 가능: yolov5n - yolov5x6, custom\n",
    "    \n",
    "    # 이미지\n",
    "    img = image_path  # or file, Path, PIL, OpenCV, numpy, list\n",
    "    \n",
    "    # 추론\n",
    "    results = model(img)\n",
    "    \n",
    "    # 결과 출력\n",
    "    results.print()  # 다른 옵션: .show(), .save(), .crop(), .pandas() 등\n",
    "    \n",
    "    # 결과 이미지 보여주기\n",
    "    results.show()\n",
    "\n",
    "def crop_book(image_path, left_half_path='C:/Users/peter/capstone/onePage/left_half.jpg', right_half_path='C:/Users/peter/capstone/onePage/right_half.jpg'):\n",
    "    \"\"\"\n",
    "    이미지에서 'book' 객체를 탐지하고 가장 높은 신뢰도를 가진 'book' 객체의 이미지를 가로로 반으로 나누어 저장합니다.\n",
    "\n",
    "    Args:\n",
    "    - image_path: 탐지를 수행할 이미지 경로\n",
    "    - left_half_path: 왼쪽 반쪽 이미지를 저장할 경로\n",
    "    - right_half_path: 오른쪽 반쪽 이미지를 저장할 경로\n",
    "    \"\"\"\n",
    "    # 모델 로드\n",
    "    model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\")  # YOLOv5 모델 버전 선택\n",
    "\n",
    "    # 추론 수행\n",
    "    results = model(image_path)\n",
    "\n",
    "    # detected된 모든 객체를 pandas 데이터프레임 형태로 변환\n",
    "    df = results.pandas().xyxy[0]\n",
    "\n",
    "    # 'book' 클래스의 객체들만 필터링\n",
    "    book_df = df[df['name'] == 'book']\n",
    "\n",
    "    # confidence가 가장 높은 'book' 객체 찾기\n",
    "    if not book_df.empty:\n",
    "        highest_conf_row = book_df.loc[book_df['confidence'].idxmax()]\n",
    "        \n",
    "        # 이미지 로드\n",
    "        img = Image.open(image_path)\n",
    "        \n",
    "        # 바운딩 박스로 이미지 자르기\n",
    "        cropped = img.crop((int(highest_conf_row['xmin']), int(highest_conf_row['ymin']), int(highest_conf_row['xmax']), int(highest_conf_row['ymax'])))\n",
    "        \n",
    "        # 이미지를 가로로 반으로 나누기\n",
    "        width, height = cropped.size\n",
    "        left_half = cropped.crop((0, 0, width/2, height))\n",
    "        right_half = cropped.crop((width/2, 0, width, height))\n",
    "        \n",
    "        # 나눠진 이미지 파일 저장\n",
    "        left_half.save(left_half_path)\n",
    "        right_half.save(right_half_path)\n",
    "        \n",
    "        return True  # 성공적으로 처리됨\n",
    "    else:\n",
    "        print(\"탐지된 'book'이 없습니다.\")\n",
    "        return False  # 'book'이 탐지되지 않음\n",
    "\n",
    "def text_detection(left_img_path, right_img_path):\n",
    "    # easyocr Reader 생성 (한국어와 영어 인식을 위해 'ko'와 'en' 설정)\n",
    "    reader = easyocr.Reader(['ko', 'en'], gpu=False)\n",
    "\n",
    "    # 이미지 읽기\n",
    "    left_img = cv2.imread(left_img_path)\n",
    "    right_img = cv2.imread(right_img_path)\n",
    "\n",
    "    # 텍스트를 저장할 리스트 초기화\n",
    "    recognized_texts = []\n",
    "\n",
    "    # 이미지에서 텍스트 인식 및 바운드 박스 그리기 함수 정의\n",
    "    def recognize_text_and_draw_bbox(image, image_path, title):\n",
    "        result = reader.readtext(image)\n",
    "        for (bbox, text, prob) in result:\n",
    "            # 인식된 텍스트를 리스트에 추가\n",
    "            recognized_texts.append(text)\n",
    "            # 바운드 박스 좌표 추출 및 그리기\n",
    "            (top_left, top_right, bottom_right, bottom_left) = bbox\n",
    "            top_left = (int(top_left[0]), int(top_left[1]))\n",
    "            bottom_right = (int(bottom_right[0]), int(bottom_right[1]))\n",
    "            cv2.rectangle(image, top_left, bottom_right, (0, 255, 0), 2)\n",
    "\n",
    "        # 이미지 저장 및 표시\n",
    "        cv2.imwrite(image_path, image)\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    # 왼쪽 및 오른쪽 이미지에 대해 텍스트 인식 및 바운드 박스 그리기 수행\n",
    "    recognize_text_and_draw_bbox(left_img, 'C:/Users/peter/capstone/onePage/left_half.jpg', \"Left Page with Bounding Boxes\")\n",
    "    recognize_text_and_draw_bbox(right_img, 'C:/Users/peter/capstone/onePage/right_half.jpg', \"Right Page with Bounding Boxes\")\n",
    "\n",
    "    # 인식된 텍스트 리스트 출력\n",
    "    print(\"인식된 텍스트들:\")\n",
    "\n",
    "    print(''.join(map(str, recognized_texts)))\n",
    "    \n",
    "    #for text in recognized_texts:\n",
    "    #    print(text, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
