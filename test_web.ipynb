{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e65f11b6-e565-4af8-9d9f-1c068e984012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "^C\n",
      "^C\n",
      "^C\n",
      "^C\n",
      "^C\n",
      "^C\n",
      "Requirement already satisfied: flask in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from flask) (3.0.2)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from flask) (1.8.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from Jinja2>=3.1.2->flask) (2.1.3)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: pyserial in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: nbimporter in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook braille_translate.ipynb to script\n",
      "[NbConvertApp] Writing 6609 bytes to braille_translate.py\n"
     ]
    }
   ],
   "source": [
    "!pip install flask\n",
    "!pip install pyserial\n",
    "!pip install opencv-python\n",
    "!pip install nbimporter\n",
    "!pip install torch torchaudio torchvision\n",
    "!jupyter nbconvert --to script text_processing.ipynb\n",
    "!jupyter nbconvert --to script camera_operation.ipynb\n",
    "!jupyter nbconvert --to script braille_translate.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6880ebd-583d-4769-b4ca-c71fb2531a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.0.18:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [01/Jun/2024 17:19:26] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Jun/2024 17:19:27] \"GET /video HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Jun/2024 17:19:53] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Jun/2024 17:19:53] \"GET /video HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, Response\n",
    "import cv2\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# 웹캠에서 비디오 캡쳐\n",
    "camera = cv2.VideoCapture(1)\n",
    "camera.set(cv2.CAP_PROP_FRAME_WIDTH, 480)\n",
    "camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 270)\n",
    "\n",
    "def generate_frames():\n",
    "    while True:\n",
    "        success, frame = camera.read()  # 카메라로부터 프레임 읽기\n",
    "        if not success:\n",
    "            break\n",
    "        else:\n",
    "            ret, buffer = cv2.imencode('.jpg', frame)\n",
    "            frame = buffer.tobytes()\n",
    "            yield (b'--frame\\r\\n'\n",
    "                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('braille.html')\n",
    "\n",
    "@app.route('/video')\n",
    "def video():\n",
    "    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False, host='0.0.0.0', port=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e9498ea-75ad-4a70-b82a-1b1fabf2a653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: torch in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (2.2.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (0.17.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "^C\n",
      "Requirement already satisfied: pillow in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (10.3.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, Response\n",
    "import serial\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import threading\n",
    "import subprocess\n",
    "import nbimporter\n",
    "from camera_operation import taking_picture\n",
    "from image_processing import crop_image\n",
    "from text_processing import text_correction, text_detection\n",
    "from braille_translate import text_to_braille\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# 연결할 시리얼 포트와 baudrate 설정\n",
    "ser = serial.Serial('COM7', 9600)\n",
    "\n",
    "# 변수 선언 및 초기화\n",
    "camera = cv2.VideoCapture(2)\n",
    "recognized_texts_global = []\n",
    "current_text_index = 0\n",
    "braille_texts = []\n",
    "\n",
    "def read_from_port(ser):\n",
    "    # 인식된 텍스트를 저장할 전역 변수\n",
    "    global recognized_texts_global\n",
    "    global current_text_index\n",
    "    global braille_texts\n",
    "\n",
    "    while True:\n",
    "        reading = ser.readline().decode().strip()  # 끝의 줄바꿈 제거\n",
    "        print(\"===============  Received from Arduino -> \", reading, \"  ===============\")\n",
    "        if reading == \"Take Picture\":\n",
    "            # 이미지 촬영\n",
    "            print(\"< 이미지 촬영 >\")\n",
    "            img_path = taking_picture(camera)\n",
    "\n",
    "            print(\"< 텍스트 인식 >\")\n",
    "            recognized_texts = text_detection(img_path)\n",
    "            # 인식된 텍스트 처리\n",
    "            words_list = [word for text in recognized_texts for word in text.split()]\n",
    "            corrected_texts = text_correction(words_list)\n",
    "            filtered_texts = [text for text in corrected_texts if text.strip()]\n",
    "            \n",
    "            print(\"인식된 텍스트 : \", filtered_texts)\n",
    "           # recognized_texts_global = filtered_texts  # 새로운 텍스트로 업데이트\n",
    "           # current_text_index = 0  # 새로운 텍스트 리스트로 업데이트되면 인덱스 초기화\n",
    "\n",
    "            \n",
    "            # 텍스트를 점자로 변환하여 저장\n",
    "            print(\"< 텍스트 점자로 변환 >\")\n",
    "            braille_texts = text_to_braille(filtered_texts)\n",
    "            print(\"점자 텍스트 : \", braille_texts)\n",
    "            recognized_texts_global = braille_texts\n",
    "            current_text_index = 0\n",
    "        elif reading == \"Next\":\n",
    "            next_text()\n",
    "            \n",
    "        elif reading == \"Previous\":\n",
    "            previous_text()\n",
    "            \n",
    "def next_text():\n",
    "    global current_text_index\n",
    "    \n",
    "    if len(recognized_texts_global) == 0:\n",
    "        print(\"리스트가 비어있습니다.\")\n",
    "        \n",
    "    elif current_text_index < len(recognized_texts_global) - 1:\n",
    "        send_text_to_arduino(recognized_texts_global[current_text_index])\n",
    "        current_text_index += 1\n",
    "    else:\n",
    "        print(\"리스트의 끝점입니다.\")\n",
    "\n",
    "def previous_text():\n",
    "    global current_text_index\n",
    "    \n",
    "    if len(recognized_texts_global) == 0:\n",
    "        print(\"리스트가 비어있습니다.\")\n",
    "        \n",
    "    elif current_text_index > 0:\n",
    "        send_text_to_arduino(recognized_texts_global[current_text_index])\n",
    "        current_text_index -= 1\n",
    "        \n",
    "    else:\n",
    "        print(\"리스트의 시작점입니다.\")\n",
    "\n",
    "def send_text_to_arduino(text):\n",
    "    print(\"Sending to Arduino:\", text)\n",
    "    ser.write((text + \"\\n\").encode())\n",
    "\n",
    "# 프로그램 종료 시 자원 해제\n",
    "def release_resources():\n",
    "    camera.release()\n",
    "    ser.close()\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('braille.html')\n",
    "\n",
    "@app.route('/video')\n",
    "def video():\n",
    "    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "thread = threading.Thread(target=read_from_port, args=(ser,))\n",
    "thread.start()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False, host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b636c2c1-2177-4d3e-a27e-effa7c8f5900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://172.16.18.234:5000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-1 이미지 촬영 진행 중입니다.\n",
      "[Error] 이미지 촬영에 실패했습니다. 카메라 연결을 확인해 주세요\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, Response, jsonify\n",
    "import serial\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import io\n",
    "import threading\n",
    "import subprocess\n",
    "import nbimporter\n",
    "from camera_operation import taking_picture\n",
    "from text_processing import text_correction, text_detection\n",
    "from braille_translate import text_to_braille\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# 연결할 시리얼 포트와 baudrate 설정\n",
    "ser = serial.Serial('COM7', 9600)\n",
    "\n",
    "# 변수 선언 및 초기화\n",
    "camera = cv2.VideoCapture(1)\n",
    "recognized_texts_global = []\n",
    "current_text_index = 0\n",
    "braille_texts = []\n",
    "log_messages = []\n",
    "captured_image_path = None\n",
    "\n",
    "def read_from_port(ser):\n",
    "    global recognized_texts_global, current_text_index, braille_texts, log_messages, captured_image_path\n",
    "\n",
    "    while True:\n",
    "        reading = ser.readline().decode().strip()  # 끝의 줄바꿈 제거\n",
    "        log_messages.append(f\"Received from Arduino -> {reading}\")\n",
    "        if reading == \"Take Picture\":\n",
    "            # 이미지 촬영\n",
    "            log_messages.append(\"< 1 - 이미지 촬영 >\")\n",
    "            img_path = taking_picture(camera)\n",
    "            captured_image_path = img_path\n",
    "\n",
    "            # 널값인지 검사\n",
    "            if img_path is None:\n",
    "                continue\n",
    "\n",
    "            # 텍스트 인식\n",
    "            log_messages.append(\"< 2 - 텍스트 인식 >\")\n",
    "            recognized_texts = text_detection(img_path)\n",
    "                \n",
    "            # 인식된 텍스트 처리\n",
    "            words_list = [word for text in recognized_texts for word in text.split()]\n",
    "            try:\n",
    "                corrected_texts = text_correction(words_list)\n",
    "            except ValueError as e:\n",
    "                log_messages.append(f\"예외 발생: {e}\")\n",
    "                continue\n",
    "            filtered_texts = [text for text in corrected_texts if text.strip()]\n",
    "            \n",
    "            log_messages.append(f\"인식된 텍스트 >>> {filtered_texts}\")\n",
    "            recognized_texts_global = filtered_texts  # 새로운 텍스트로 업데이트\n",
    "            current_text_index = 0  # 새로운 텍스트 리스트로 업데이트되면 인덱스 초기화\n",
    "\n",
    "            \n",
    "            # 텍스트를 점자로 변환하여 저장\n",
    "            log_messages.append(\"< 3 - 텍스트 점자로 변환 >\")\n",
    "            braille_texts = text_to_braille(filtered_texts)\n",
    "            log_messages.append(f\"점자 텍스트 >>> {braille_texts}\")\n",
    "            \n",
    "        elif reading == \"Next\":\n",
    "            next_text()\n",
    "            \n",
    "        elif reading == \"Previous\":\n",
    "            previous_text()\n",
    "            \n",
    "def next_text():\n",
    "    global current_text_index, log_messages\n",
    "    \n",
    "    if len(recognized_texts_global) == 0:\n",
    "        log_messages.append(\"[Warning] 리스트가 비어있습니다.\")\n",
    "        \n",
    "    elif current_text_index < len(recognized_texts_global) - 1:\n",
    "        send_text_to_arduino(recognized_texts_global[current_text_index])\n",
    "        current_text_index += 1\n",
    "        log_messages.append(f\"Sending to Arduino: {recognized_texts_global[current_text_index]}\")\n",
    "    else:\n",
    "        log_messages.append(\"리스트의 끝점입니다.\")\n",
    "\n",
    "def previous_text():\n",
    "    global current_text_index, log_messages\n",
    "    \n",
    "    if len(recognized_texts_global) == 0:\n",
    "        log_messages.append(\"[Warning] 리스트가 비어있습니다.\")\n",
    "        \n",
    "    elif current_text_index > 0:\n",
    "        send_text_to_arduino(recognized_texts_global[current_text_index])\n",
    "        current_text_index -= 1\n",
    "        log_messages.append(f\"Sending to Arduino: {recognized_texts_global[current_text_index]}\")\n",
    "        \n",
    "    else:\n",
    "        log_messages.append(\"리스트의 시작점입니다.\")\n",
    "\n",
    "def send_text_to_arduino(text):\n",
    "    ser.write((text + \"\\n\").encode())\n",
    "\n",
    "# 프로그램 종료 시 자원 해제\n",
    "def release_resources():\n",
    "    camera.release()\n",
    "    ser.close()\n",
    "\n",
    "def generate_frames():\n",
    "    while True:\n",
    "        success, frame = camera.read()  # 카메라로부터 프레임 읽기\n",
    "        if not success:\n",
    "            break\n",
    "        else:\n",
    "            ret, buffer = cv2.imencode('.jpg', frame)\n",
    "            frame = buffer.tobytes()\n",
    "            yield (b'--frame\\r\\n'\n",
    "                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('test1.html', captured_image_path=captured_image_path, log_messages=log_messages)\n",
    "\n",
    "@app.route('/video')\n",
    "def video():\n",
    "    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "@app.route('/labeled-image-url')\n",
    "def labeled_image_url():\n",
    "    # 외부 서버에 저장된 이미지의 URL\n",
    "    external_image_url = ''\n",
    "    # 외부 이미지 URL을 반환합니다.\n",
    "    return external_image_url\n",
    "\n",
    "@app.route('/logs')\n",
    "def logs():\n",
    "    return jsonify(log_messages)\n",
    "\n",
    "thread = threading.Thread(target=read_from_port, args=(ser,))\n",
    "thread.start()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False, host='0.0.0.0', port=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d54bc9-a527-43df-86cd-989bbf5df0a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
