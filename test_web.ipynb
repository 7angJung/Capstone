{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e65f11b6-e565-4af8-9d9f-1c068e984012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "^C\n",
      "^C\n",
      "^C\n",
      "^C\n",
      "^C\n",
      "^C\n",
      "Requirement already satisfied: flask in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from flask) (3.0.2)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from flask) (1.8.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from Jinja2>=3.1.2->flask) (2.1.3)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: pyserial in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: nbimporter in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook braille_translate.ipynb to script\n",
      "[NbConvertApp] Writing 6609 bytes to braille_translate.py\n"
     ]
    }
   ],
   "source": [
    "!pip install flask\n",
    "!pip install pyserial\n",
    "!pip install opencv-python\n",
    "!pip install nbimporter\n",
    "!pip install torch torchaudio torchvision\n",
    "!jupyter nbconvert --to script text_processing.ipynb\n",
    "!jupyter nbconvert --to script camera_operation.ipynb\n",
    "!jupyter nbconvert --to script braille_translate.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6880ebd-583d-4769-b4ca-c71fb2531a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.0.18:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [01/Jun/2024 17:19:26] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Jun/2024 17:19:27] \"GET /video HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Jun/2024 17:19:53] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Jun/2024 17:19:53] \"GET /video HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, Response\n",
    "import cv2\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# 웹캠에서 비디오 캡쳐\n",
    "camera = cv2.VideoCapture(1)\n",
    "camera.set(cv2.CAP_PROP_FRAME_WIDTH, 480)\n",
    "camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 270)\n",
    "\n",
    "def generate_frames():\n",
    "    while True:\n",
    "        success, frame = camera.read()  # 카메라로부터 프레임 읽기\n",
    "        if not success:\n",
    "            break\n",
    "        else:\n",
    "            ret, buffer = cv2.imencode('.jpg', frame)\n",
    "            frame = buffer.tobytes()\n",
    "            yield (b'--frame\\r\\n'\n",
    "                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('braille.html')\n",
    "\n",
    "@app.route('/video')\n",
    "def video():\n",
    "    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False, host='0.0.0.0', port=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e9498ea-75ad-4a70-b82a-1b1fabf2a653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: torch in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (2.2.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (0.17.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "^C\n",
      "Requirement already satisfied: pillow in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (10.3.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, Response\n",
    "import serial\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import threading\n",
    "import subprocess\n",
    "import nbimporter\n",
    "from camera_operation import taking_picture\n",
    "from image_processing import crop_image\n",
    "from text_processing import text_correction, text_detection\n",
    "from braille_translate import text_to_braille\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# 연결할 시리얼 포트와 baudrate 설정\n",
    "ser = serial.Serial('COM7', 9600)\n",
    "\n",
    "# 변수 선언 및 초기화\n",
    "camera = cv2.VideoCapture(2)\n",
    "recognized_texts_global = []\n",
    "current_text_index = 0\n",
    "braille_texts = []\n",
    "\n",
    "def read_from_port(ser):\n",
    "    # 인식된 텍스트를 저장할 전역 변수\n",
    "    global recognized_texts_global\n",
    "    global current_text_index\n",
    "    global braille_texts\n",
    "\n",
    "    while True:\n",
    "        reading = ser.readline().decode().strip()  # 끝의 줄바꿈 제거\n",
    "        print(\"===============  Received from Arduino -> \", reading, \"  ===============\")\n",
    "        if reading == \"Take Picture\":\n",
    "            # 이미지 촬영\n",
    "            print(\"< 이미지 촬영 >\")\n",
    "            img_path = taking_picture(camera)\n",
    "\n",
    "            print(\"< 텍스트 인식 >\")\n",
    "            recognized_texts = text_detection(img_path)\n",
    "            # 인식된 텍스트 처리\n",
    "            words_list = [word for text in recognized_texts for word in text.split()]\n",
    "            corrected_texts = text_correction(words_list)\n",
    "            filtered_texts = [text for text in corrected_texts if text.strip()]\n",
    "            \n",
    "            print(\"인식된 텍스트 : \", filtered_texts)\n",
    "           # recognized_texts_global = filtered_texts  # 새로운 텍스트로 업데이트\n",
    "           # current_text_index = 0  # 새로운 텍스트 리스트로 업데이트되면 인덱스 초기화\n",
    "\n",
    "            \n",
    "            # 텍스트를 점자로 변환하여 저장\n",
    "            print(\"< 텍스트 점자로 변환 >\")\n",
    "            braille_texts = text_to_braille(filtered_texts)\n",
    "            print(\"점자 텍스트 : \", braille_texts)\n",
    "            recognized_texts_global = braille_texts\n",
    "            current_text_index = 0\n",
    "        elif reading == \"Next\":\n",
    "            next_text()\n",
    "            \n",
    "        elif reading == \"Previous\":\n",
    "            previous_text()\n",
    "            \n",
    "def next_text():\n",
    "    global current_text_index\n",
    "    \n",
    "    if len(recognized_texts_global) == 0:\n",
    "        print(\"리스트가 비어있습니다.\")\n",
    "        \n",
    "    elif current_text_index < len(recognized_texts_global) - 1:\n",
    "        send_text_to_arduino(recognized_texts_global[current_text_index])\n",
    "        current_text_index += 1\n",
    "    else:\n",
    "        print(\"리스트의 끝점입니다.\")\n",
    "\n",
    "def previous_text():\n",
    "    global current_text_index\n",
    "    \n",
    "    if len(recognized_texts_global) == 0:\n",
    "        print(\"리스트가 비어있습니다.\")\n",
    "        \n",
    "    elif current_text_index > 0:\n",
    "        send_text_to_arduino(recognized_texts_global[current_text_index])\n",
    "        current_text_index -= 1\n",
    "        \n",
    "    else:\n",
    "        print(\"리스트의 시작점입니다.\")\n",
    "\n",
    "def send_text_to_arduino(text):\n",
    "    print(\"Sending to Arduino:\", text)\n",
    "    ser.write((text + \"\\n\").encode())\n",
    "\n",
    "# 프로그램 종료 시 자원 해제\n",
    "def release_resources():\n",
    "    camera.release()\n",
    "    ser.close()\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('braille.html')\n",
    "\n",
    "@app.route('/video')\n",
    "def video():\n",
    "    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "thread = threading.Thread(target=read_from_port, args=(ser,))\n",
    "thread.start()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False, host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b636c2c1-2177-4d3e-a27e-effa7c8f5900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: easyocr in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (1.7.1)\n",
      "Requirement already satisfied: torch in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from easyocr) (2.2.1)\n",
      "Requirement already satisfied: torchvision>=0.5 in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from easyocr) (0.17.1)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (4.8.0.74)\n",
      "Requirement already satisfied: scipy in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (1.12.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (1.26.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (10.3.0)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from easyocr) (0.22.0)\n",
      "Requirement already satisfied: python-bidi in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (0.4.2)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (6.0.1)\n",
      "Requirement already satisfied: Shapely in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (2.0.3)\n",
      "Requirement already satisfied: pyclipper in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (1.3.0.post5)\n",
      "Requirement already satisfied: ninja in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from easyocr) (1.11.1.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch->easyocr) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch->easyocr) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch->easyocr) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch->easyocr) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch->easyocr) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch->easyocr) (2024.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from python-bidi->easyocr) (1.16.0)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from scikit-image->easyocr) (2.34.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from scikit-image->easyocr) (2024.2.12)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from scikit-image->easyocr) (23.2)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from scikit-image->easyocr) (0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from jinja2->torch->easyocr) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from sympy->torch->easyocr) (1.3.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: torch in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (2.2.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (0.17.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\peter\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (4.8.0.74)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (from opencv-python-headless) (1.26.4)\n",
      "Requirement already satisfied: pyspellchecker in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: wordninja in c:\\users\\peter\\anaconda3\\envs\\capstone\\lib\\site-packages (2.0.0)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'version'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnbimporter\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcamera_operation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m taking_picture\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtext_processing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m text_correction, text_detection\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbraille_translate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m text_to_braille\n\u001b[0;32m     13\u001b[0m app \u001b[38;5;241m=\u001b[39m Flask(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[1;32m~\\capstone\\text_processing.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01measyocr\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\easyocr\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01measyocr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Reader\n\u001b[0;32m      3\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1.7.1\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\easyocr\\easyocr.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecognition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_recognizer, get_text\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m group_text_box, get_image_list, calculate_md5, get_paragraph,\\\n\u001b[0;32m      5\u001b[0m                    download_and_unzip, printProgressBar, diff, reformat_input,\\\n\u001b[0;32m      6\u001b[0m                    make_rotated_img_list, set_result_with_confidence,\\\n\u001b[0;32m      7\u001b[0m                    reformat_input_batched, merge_to_free\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\easyocr\\recognition.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OrderedDict\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodulefinder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malexnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdensenet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mefficientnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\convnext.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Permute\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstochastic_depth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StochasticDepth\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_presets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageClassification\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _log_api_usage_once\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\ops\\__init__.py:23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgiou_loss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generalized_box_iou_loss\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Conv3dNormActivation, FrozenBatchNorm2d, MLP, Permute, SqueezeExcitation\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpoolers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultiScaleRoIAlign\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mps_roi_align\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ps_roi_align, PSRoIAlign\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mps_roi_pool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ps_roi_pool, PSRoIPool\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\ops\\poolers.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mboxes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m box_area\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _log_api_usage_once\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mroi_align\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roi_align\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# copying result_idx_in_level to a specific index in result[]\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# is not supported by ONNX tracing yet.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# _onnx_merge_levels() is an implementation supported by ONNX\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# that merges the levels to the right indices\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39munused\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_onnx_merge_levels\u001b[39m(levels: Tensor, unmerged_results: List[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\ops\\roi_align.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Union\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\_dynamo\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m allowed_functions, convert_frame, eval_frame, resume_execution\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcode_context\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m code_context\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\_dynamo\\allowed_functions.py:28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecated\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdeprecated_func\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_symbolic_trace\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_fx_tracing\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexternal_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_compiling\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hashable, is_safe_constant, NP_SUPPORTED_MODULES\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\_dynamo\\config.py:288\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG_DIR_VAR_NAME \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[0;32m    285\u001b[0m     debug_dir_root \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(  \u001b[38;5;66;03m# [@compile_ignored: debug]\u001b[39;00m\n\u001b[0;32m    286\u001b[0m         os\u001b[38;5;241m.\u001b[39menviron[DEBUG_DIR_VAR_NAME], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_compile_debug\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m     )\n\u001b[1;32m--> 288\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_fbcode():\n\u001b[0;32m    289\u001b[0m     debug_dir_root \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(  \u001b[38;5;66;03m# [@compile_ignored: debug]\u001b[39;00m\n\u001b[0;32m    290\u001b[0m         tempfile\u001b[38;5;241m.\u001b[39mgettempdir(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_compile_debug\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    291\u001b[0m     )\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\_dynamo\\config.py:279\u001b[0m, in \u001b[0;36mis_fbcode\u001b[1;34m()\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_fbcode\u001b[39m():\n\u001b[1;32m--> 279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39mversion, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgit_version\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\__init__.py:1938\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m   1935\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[0;32m   1936\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m-> 1938\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'version'"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, Response, jsonify\n",
    "import serial\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import threading\n",
    "import subprocess\n",
    "import nbimporter\n",
    "from camera_operation import taking_picture\n",
    "from text_processing import text_correction, text_detection\n",
    "from braille_translate import text_to_braille\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# 연결할 시리얼 포트와 baudrate 설정\n",
    "ser = serial.Serial('COM7', 9600)\n",
    "\n",
    "# 변수 선언 및 초기화\n",
    "camera = cv2.VideoCapture(1)\n",
    "recognized_texts_global = []\n",
    "current_text_index = 0\n",
    "braille_texts = []\n",
    "log_messages = []\n",
    "captured_image_path = None\n",
    "\n",
    "def read_from_port(ser):\n",
    "    global recognized_texts_global, current_text_index, braille_texts, log_messages, captured_image_path\n",
    "\n",
    "    while True:\n",
    "        reading = ser.readline().decode().strip()  # 끝의 줄바꿈 제거\n",
    "        log_messages.append(f\"Received from Arduino -> {reading}\")\n",
    "        if reading == \"Take Picture\":\n",
    "            # 이미지 촬영\n",
    "            log_messages.append(\"< 1 - 이미지 촬영 >\")\n",
    "            img_path = taking_picture(camera)\n",
    "            captured_image_path = img_path\n",
    "\n",
    "            # 널값인지 검사\n",
    "            if img_path is None:\n",
    "                continue\n",
    "\n",
    "            # 텍스트 인식\n",
    "            log_messages.append(\"< 2 - 텍스트 인식 >\")\n",
    "            recognized_texts = text_detection(img_path)\n",
    "                \n",
    "            # 인식된 텍스트 처리\n",
    "            words_list = [word for text in recognized_texts for word in text.split()]\n",
    "            try:\n",
    "                corrected_texts = text_correction(words_list)\n",
    "            except ValueError as e:\n",
    "                log_messages.append(f\"예외 발생: {e}\")\n",
    "                continue\n",
    "            filtered_texts = [text for text in corrected_texts if text.strip()]\n",
    "            \n",
    "            log_messages.append(f\"인식된 텍스트 >>> {filtered_texts}\")\n",
    "            recognized_texts_global = filtered_texts  # 새로운 텍스트로 업데이트\n",
    "            current_text_index = 0  # 새로운 텍스트 리스트로 업데이트되면 인덱스 초기화\n",
    "\n",
    "            \n",
    "            # 텍스트를 점자로 변환하여 저장\n",
    "            log_messages.append(\"< 3 - 텍스트 점자로 변환 >\")\n",
    "            braille_texts = text_to_braille(filtered_texts)\n",
    "            log_messages.append(f\"점자 텍스트 >>> {braille_texts}\")\n",
    "            \n",
    "        elif reading == \"Next\":\n",
    "            next_text()\n",
    "            \n",
    "        elif reading == \"Previous\":\n",
    "            previous_text()\n",
    "            \n",
    "def next_text():\n",
    "    global current_text_index, log_messages\n",
    "    \n",
    "    if len(recognized_texts_global) == 0:\n",
    "        log_messages.append(\"[Warning] 리스트가 비어있습니다.\")\n",
    "        \n",
    "    elif current_text_index < len(recognized_texts_global) - 1:\n",
    "        send_text_to_arduino(recognized_texts_global[current_text_index])\n",
    "        current_text_index += 1\n",
    "        log_messages.append(f\"Sending to Arduino: {recognized_texts_global[current_text_index]}\")\n",
    "    else:\n",
    "        log_messages.append(\"리스트의 끝점입니다.\")\n",
    "\n",
    "def previous_text():\n",
    "    global current_text_index, log_messages\n",
    "    \n",
    "    if len(recognized_texts_global) == 0:\n",
    "        log_messages.append(\"[Warning] 리스트가 비어있습니다.\")\n",
    "        \n",
    "    elif current_text_index > 0:\n",
    "        send_text_to_arduino(recognized_texts_global[current_text_index])\n",
    "        current_text_index -= 1\n",
    "        log_messages.append(f\"Sending to Arduino: {recognized_texts_global[current_text_index]}\")\n",
    "        \n",
    "    else:\n",
    "        log_messages.append(\"리스트의 시작점입니다.\")\n",
    "\n",
    "def send_text_to_arduino(text):\n",
    "    ser.write((text + \"\\n\").encode())\n",
    "\n",
    "# 프로그램 종료 시 자원 해제\n",
    "def release_resources():\n",
    "    camera.release()\n",
    "    ser.close()\n",
    "\n",
    "def generate_frames():\n",
    "    while True:\n",
    "        success, frame = camera.read()  # 카메라로부터 프레임 읽기\n",
    "        if not success:\n",
    "            break\n",
    "        else:\n",
    "            ret, buffer = cv2.imencode('.jpg', frame)\n",
    "            frame = buffer.tobytes()\n",
    "            yield (b'--frame\\r\\n'\n",
    "                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('test1.html', captured_image_path=captured_image_path, log_messages=log_messages)\n",
    "\n",
    "@app.route('/video')\n",
    "def video():\n",
    "    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "@app.route('/labeled-image-url')\n",
    "def labeled_image_url():\n",
    "    # 외부 서버에 저장된 이미지의 URL\n",
    "    external_image_url = ''\n",
    "    # 외부 이미지 URL을 반환합니다.\n",
    "    return external_image_url\n",
    "\n",
    "@app.route('/logs')\n",
    "def logs():\n",
    "    return jsonify(log_messages)\n",
    "\n",
    "thread = threading.Thread(target=read_from_port, args=(ser,))\n",
    "thread.start()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False, host='0.0.0.0', port=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d54bc9-a527-43df-86cd-989bbf5df0a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
